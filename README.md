# Real-time-sign-language-detection-Complex-gesture-navigation
Our project is based on CNN(conventional neural network) which can understand Indian Sign Language and translate them into English text and voices.

Problem Statement :-

➢ As we all know that everyone cannot understand sign languages and so there is a 
   communication gap between differently abled people(those who are unable to 
   speak or can’t hear) and common folks.

➢ There are a lots of deaf and dumb/mute people in our country those who are 
   suffering from communication barrier due to lack of education, facilities 
   provided by the government and lack of technology from which they can’t    
   communicate with ease in public.

➢ Even the people those who are not suffering from these disabilities are not
   educated enough so they can't communicate with those who are mute.

Solution to the above problem :-

➢Real time sign language detection
    
    ✦Sign language will be converted into voice or in 
       texts by detecting signs in real time or vice versa.
    
    ✦It will make it easy to educate mute people and make
       them independent.
    
    ✦It will also make people learn sign language.

How it Works?
1. It detects hand signs made by the user and store it as keypoints.
2. Then it matches the keypoints with the previously collected data to recognize the sign.
3. Displays the word as a text or convert it to voice or vice-versa.

Technology Used :- Python, Mediapipe, Opencv-python, Sklearn, Tensorflow==2.4.1, Keras, Tensorflow-gpu==2.4.1, Matplotlib, Pyttsx3




